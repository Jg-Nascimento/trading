{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stockPrice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIu3NxY1gKoFRG8ta6d2D4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prevencao/trading/blob/master/stockPrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxL_lHmA2pcR",
        "colab_type": "text"
      },
      "source": [
        "https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cNUIxSt2p5v",
        "colab_type": "text"
      },
      "source": [
        "##**Como prever os preços das ações em Python usando TensorFlow 2 e Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agC4qlnH2gdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "e6c86c7a-941c-41bd-f3d4-cb6c182ed0c2"
      },
      "source": [
        "!pip3 install tensorflow pandas numpy matplotlib yahoo_fin sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Collecting yahoo_fin\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/5c/6bf0c0147cc94d643e2a2413d0a9b27967e964ee99f88f26db93a0b963b8/yahoo_fin-0.8.6-py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVjqDOvo2-uY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "26a0162f-9785-49c4-9f3b-d7c5b530c02c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning - Certain functionality \n",
            "             requires requests_html, which is not installed.\n",
            "             \n",
            "             Install using: \n",
            "             pip install requests_html\n",
            "             \n",
            "             After installation, you may have to restart your Python session.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s19nMnAg3A5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''definir semente, para que possamos obter os \n",
        "mesmos resultados depois de executar novamente \n",
        "várias vezes'''\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVNJFQ7F3O7m",
        "colab_type": "text"
      },
      "source": [
        "## Preparando o DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx5v6hkR3BAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
        "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    # shift the last sequence by -1\n",
        "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jynawFG3fqf",
        "colab_type": "text"
      },
      "source": [
        "## Criando o Modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAYq_9jm3jaL",
        "colab_type": "text"
      },
      "source": [
        "Agora que temos uma função adequada para carregar e preparar o conjunto de \n",
        "\n",
        "dados, precisamos de outra função central para construir nosso modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSYDh_0P3A9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZhlaojYbCTo",
        "colab_type": "text"
      },
      "source": [
        "## Treinando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiUGAAak2--n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Window size or the sequence length\n",
        "N_STEPS = 100\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 1\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "### model parameters\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "### training parameters\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 400\n",
        "# Apple stock market\n",
        "ticker = \"AAPL\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "  model_name += \"-b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SspYdHZT2_DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cria essas pastas se elas não existirem\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0B_53yEbax6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8c147de-f21f-4bdc-9d1d-98e8802d0ce8"
      },
      "source": [
        "# carrega os dados\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "# salva o dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "# constroi o modelo\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "# alguns retornos do TensorFlow\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "  1/124 [..............................] - ETA: 0s - loss: 0.0111 - mean_absolute_error: 0.0670WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "  2/124 [..............................] - ETA: 4s - loss: 0.0067 - mean_absolute_error: 0.0540WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.0613s). Check your callbacks.\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.5729e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 00001: val_loss improved from inf to 0.00024, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 6.4804e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3731e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 2/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 3.9408e-04 - mean_absolute_error: 0.0127\n",
            "Epoch 00002: val_loss did not improve from 0.00024\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 3.9650e-04 - mean_absolute_error: 0.0127 - val_loss: 4.5055e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 3/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 4.5753e-04 - mean_absolute_error: 0.0137\n",
            "Epoch 00003: val_loss improved from 0.00024 to 0.00020, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 4.5674e-04 - mean_absolute_error: 0.0137 - val_loss: 2.0271e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 4/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 3.5895e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 00004: val_loss improved from 0.00020 to 0.00017, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 3.5601e-04 - mean_absolute_error: 0.0125 - val_loss: 1.7301e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 5/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 2.7663e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 00005: val_loss did not improve from 0.00017\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 2.7909e-04 - mean_absolute_error: 0.0110 - val_loss: 1.8461e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 6/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 3.0305e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 00006: val_loss did not improve from 0.00017\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 3.0172e-04 - mean_absolute_error: 0.0114 - val_loss: 4.4656e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 7/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 3.4790e-04 - mean_absolute_error: 0.0126\n",
            "Epoch 00007: val_loss did not improve from 0.00017\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 3.4822e-04 - mean_absolute_error: 0.0127 - val_loss: 1.8501e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 8/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 2.3320e-04 - mean_absolute_error: 0.0107\n",
            "Epoch 00008: val_loss improved from 0.00017 to 0.00014, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 2.4292e-04 - mean_absolute_error: 0.0108 - val_loss: 1.3678e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 9/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 2.6738e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00009: val_loss did not improve from 0.00014\n",
            "124/124 [==============================] - 1s 10ms/step - loss: 2.6910e-04 - mean_absolute_error: 0.0111 - val_loss: 1.6735e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 10/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 2.4161e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 00010: val_loss improved from 0.00014 to 0.00007, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 2.4282e-04 - mean_absolute_error: 0.0106 - val_loss: 6.8655e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 11/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.9722e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00011: val_loss improved from 0.00007 to 0.00006, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.9673e-04 - mean_absolute_error: 0.0101 - val_loss: 5.8675e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 12/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 1.7014e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00012: val_loss did not improve from 0.00006\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.7022e-04 - mean_absolute_error: 0.0094 - val_loss: 1.4315e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 13/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 1.7316e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00013: val_loss did not improve from 0.00006\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.7808e-04 - mean_absolute_error: 0.0095 - val_loss: 1.1276e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 14/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.8719e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00014: val_loss did not improve from 0.00006\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.8656e-04 - mean_absolute_error: 0.0103 - val_loss: 6.2759e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 15/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.7476e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00015: val_loss improved from 0.00006 to 0.00004, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.7631e-04 - mean_absolute_error: 0.0098 - val_loss: 4.3063e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 16/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.7886e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00016: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.7648e-04 - mean_absolute_error: 0.0100 - val_loss: 5.3389e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 17/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.5625e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00017: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.5772e-04 - mean_absolute_error: 0.0092 - val_loss: 4.9632e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 18/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2964e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00018: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2964e-04 - mean_absolute_error: 0.0088 - val_loss: 1.0403e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 19/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.5496e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00019: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.5445e-04 - mean_absolute_error: 0.0095 - val_loss: 1.6979e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 20/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.3705e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00020: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.3452e-04 - mean_absolute_error: 0.0090 - val_loss: 5.1316e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 21/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.2348e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00021: val_loss improved from 0.00004 to 0.00004, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.2348e-04 - mean_absolute_error: 0.0087 - val_loss: 3.5729e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 22/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 1.3303e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00022: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.3349e-04 - mean_absolute_error: 0.0088 - val_loss: 2.8144e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 23/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.2231e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00023: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2327e-04 - mean_absolute_error: 0.0088 - val_loss: 1.1066e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 24/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.3594e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00024: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.3701e-04 - mean_absolute_error: 0.0089 - val_loss: 1.7797e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 25/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.0356e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00025: val_loss did not improve from 0.00004\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0404e-04 - mean_absolute_error: 0.0081 - val_loss: 9.0067e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 26/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2735e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00026: val_loss improved from 0.00004 to 0.00003, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.2735e-04 - mean_absolute_error: 0.0089 - val_loss: 3.3507e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 27/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.1332e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00027: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1469e-04 - mean_absolute_error: 0.0087 - val_loss: 8.3284e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 28/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 1.1922e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00028: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1908e-04 - mean_absolute_error: 0.0085 - val_loss: 7.8283e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 29/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 1.1574e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00029: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1668e-04 - mean_absolute_error: 0.0083 - val_loss: 6.2420e-05 - val_mean_absolute_error: 0.0069\n",
            "Epoch 30/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.1439e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00030: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1367e-04 - mean_absolute_error: 0.0084 - val_loss: 4.7984e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 31/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0620e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00031: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0620e-04 - mean_absolute_error: 0.0083 - val_loss: 2.5321e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 32/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0993e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00032: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0993e-04 - mean_absolute_error: 0.0082 - val_loss: 3.4939e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 33/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.1303e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00033: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1291e-04 - mean_absolute_error: 0.0085 - val_loss: 8.9960e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 34/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 9.5452e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00034: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.4334e-05 - mean_absolute_error: 0.0079 - val_loss: 7.0172e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 35/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.1672e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00035: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2102e-04 - mean_absolute_error: 0.0087 - val_loss: 7.5459e-05 - val_mean_absolute_error: 0.0092\n",
            "Epoch 36/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.7028e-04 - mean_absolute_error: 0.0108\n",
            "Epoch 00036: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.6887e-04 - mean_absolute_error: 0.0109 - val_loss: 7.3221e-05 - val_mean_absolute_error: 0.0105\n",
            "Epoch 37/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.1166e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00037: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1147e-04 - mean_absolute_error: 0.0089 - val_loss: 4.1883e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 38/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.1213e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00038: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 10ms/step - loss: 9.1117e-05 - mean_absolute_error: 0.0080 - val_loss: 5.5040e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 39/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.0150e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00039: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0133e-04 - mean_absolute_error: 0.0081 - val_loss: 3.2147e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 40/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.6816e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00040: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0127e-04 - mean_absolute_error: 0.0081 - val_loss: 1.6013e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 41/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 1.1613e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00041: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1744e-04 - mean_absolute_error: 0.0088 - val_loss: 5.1027e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 42/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 1.2093e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00042: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2109e-04 - mean_absolute_error: 0.0093 - val_loss: 2.7285e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 43/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2490e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00043: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2490e-04 - mean_absolute_error: 0.0089 - val_loss: 7.3209e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 44/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1439e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00044: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1439e-04 - mean_absolute_error: 0.0086 - val_loss: 3.8709e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 45/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.3931e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00045: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.2992e-05 - mean_absolute_error: 0.0076 - val_loss: 2.5243e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 46/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 8.7873e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00046: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.7921e-05 - mean_absolute_error: 0.0076 - val_loss: 3.3637e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 47/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 9.1687e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00047: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.0738e-05 - mean_absolute_error: 0.0079 - val_loss: 3.0055e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 48/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 9.3613e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00048: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.3421e-05 - mean_absolute_error: 0.0077 - val_loss: 1.1694e-04 - val_mean_absolute_error: 0.0050\n",
            "Epoch 49/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.1377e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00049: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.1289e-04 - mean_absolute_error: 0.0085 - val_loss: 9.0216e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 50/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 1.3431e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00050: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.3353e-04 - mean_absolute_error: 0.0091 - val_loss: 6.0866e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 51/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 1.0245e-04 - mean_absolute_error: 0.0079\n",
            "Epoch 00051: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0336e-04 - mean_absolute_error: 0.0079 - val_loss: 3.0881e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 52/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.0997e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00052: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0985e-04 - mean_absolute_error: 0.0084 - val_loss: 5.4970e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 53/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 1.0476e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00053: val_loss improved from 0.00003 to 0.00002, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 10ms/step - loss: 1.0507e-04 - mean_absolute_error: 0.0083 - val_loss: 2.4550e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 54/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.3233e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00054: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.3290e-05 - mean_absolute_error: 0.0075 - val_loss: 3.2454e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 55/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9273e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00055: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.9273e-05 - mean_absolute_error: 0.0078 - val_loss: 1.8910e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 56/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.0344e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00056: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0608e-04 - mean_absolute_error: 0.0083 - val_loss: 3.9653e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 57/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8400e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00057: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.8400e-05 - mean_absolute_error: 0.0081 - val_loss: 2.1005e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 58/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 9.6296e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00058: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.5600e-05 - mean_absolute_error: 0.0080 - val_loss: 3.4670e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 59/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 9.9762e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 00059: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0005e-04 - mean_absolute_error: 0.0083 - val_loss: 5.3844e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 60/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6241e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00060: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.6241e-05 - mean_absolute_error: 0.0081 - val_loss: 3.1740e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 61/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.0144e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00061: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.0098e-05 - mean_absolute_error: 0.0079 - val_loss: 4.6267e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 62/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.0674e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00062: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0462e-04 - mean_absolute_error: 0.0082 - val_loss: 4.9889e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 63/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 9.8400e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00063: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.8291e-05 - mean_absolute_error: 0.0078 - val_loss: 1.0099e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 64/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.1141e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00064: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.0488e-05 - mean_absolute_error: 0.0077 - val_loss: 5.3746e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 65/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8586e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00065: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.8586e-05 - mean_absolute_error: 0.0078 - val_loss: 3.2106e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 66/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.0537e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00066: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.9911e-05 - mean_absolute_error: 0.0078 - val_loss: 2.7355e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 67/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.0318e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00067: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.0721e-05 - mean_absolute_error: 0.0074 - val_loss: 1.3140e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 68/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.6179e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00068: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.8304e-05 - mean_absolute_error: 0.0081 - val_loss: 7.7013e-05 - val_mean_absolute_error: 0.0074\n",
            "Epoch 69/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.2584e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00069: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.2832e-04 - mean_absolute_error: 0.0088 - val_loss: 4.4583e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 70/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5347e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00070: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.5347e-05 - mean_absolute_error: 0.0078 - val_loss: 4.2247e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 71/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 9.8247e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00071: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.8912e-05 - mean_absolute_error: 0.0080 - val_loss: 2.9573e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 72/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.0850e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00072: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0814e-04 - mean_absolute_error: 0.0085 - val_loss: 3.3693e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 73/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 8.9531e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00073: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.9428e-05 - mean_absolute_error: 0.0079 - val_loss: 2.6575e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 74/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.3546e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00074: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.2851e-05 - mean_absolute_error: 0.0075 - val_loss: 3.3176e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 75/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.1552e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00075: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.1552e-05 - mean_absolute_error: 0.0077 - val_loss: 4.6424e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 76/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 9.6051e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00076: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.4896e-05 - mean_absolute_error: 0.0080 - val_loss: 4.6258e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 77/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.9748e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00077: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.0735e-05 - mean_absolute_error: 0.0074 - val_loss: 2.6896e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 78/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.0290e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00078: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0588e-04 - mean_absolute_error: 0.0085 - val_loss: 3.0060e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 79/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 9.5407e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00079: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.5607e-05 - mean_absolute_error: 0.0078 - val_loss: 3.2836e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 80/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.8443e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00080: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.8225e-05 - mean_absolute_error: 0.0072 - val_loss: 3.1712e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 81/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.7575e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00081: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.8665e-05 - mean_absolute_error: 0.0073 - val_loss: 7.9073e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 82/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 9.5736e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00082: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.6342e-05 - mean_absolute_error: 0.0078 - val_loss: 5.0309e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 83/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.0158e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00083: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.1355e-05 - mean_absolute_error: 0.0077 - val_loss: 3.3310e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 84/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.7054e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00084: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.9379e-05 - mean_absolute_error: 0.0078 - val_loss: 9.8305e-05 - val_mean_absolute_error: 0.0104\n",
            "Epoch 85/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.7666e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00085: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.7236e-05 - mean_absolute_error: 0.0075 - val_loss: 5.5790e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 86/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 1.0419e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00086: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 1.0394e-04 - mean_absolute_error: 0.0082 - val_loss: 2.3847e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 87/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 8.2935e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00087: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.1744e-05 - mean_absolute_error: 0.0071 - val_loss: 1.7166e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 88/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1918e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00088: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.1918e-05 - mean_absolute_error: 0.0070 - val_loss: 5.8497e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 89/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.9267e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00089: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.9053e-05 - mean_absolute_error: 0.0071 - val_loss: 5.3948e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 90/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9616e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00090: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.9616e-05 - mean_absolute_error: 0.0076 - val_loss: 1.8343e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 91/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 1.1627e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00091: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.1595e-04 - mean_absolute_error: 0.0087 - val_loss: 3.4616e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 92/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 9.9428e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00092: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.9547e-05 - mean_absolute_error: 0.0081 - val_loss: 5.1798e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 93/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.1134e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00093: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.1134e-05 - mean_absolute_error: 0.0076 - val_loss: 3.6176e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 94/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2953e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00094: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2953e-05 - mean_absolute_error: 0.0071 - val_loss: 7.8451e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 95/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 8.7297e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00095: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.8166e-05 - mean_absolute_error: 0.0077 - val_loss: 4.1416e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 96/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 8.1662e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00096: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.2580e-05 - mean_absolute_error: 0.0074 - val_loss: 6.8990e-05 - val_mean_absolute_error: 0.0078\n",
            "Epoch 97/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.0896e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00097: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.0148e-05 - mean_absolute_error: 0.0074 - val_loss: 2.2282e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 98/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.7872e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00098: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.8123e-05 - mean_absolute_error: 0.0072 - val_loss: 2.8909e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 99/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.2647e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00099: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.2647e-05 - mean_absolute_error: 0.0076 - val_loss: 1.0343e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 100/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.9801e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00100: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.9943e-05 - mean_absolute_error: 0.0074 - val_loss: 2.3993e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 101/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2270e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00101: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.2270e-05 - mean_absolute_error: 0.0073 - val_loss: 4.3335e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 102/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.2128e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00102: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.2143e-04 - mean_absolute_error: 0.0088 - val_loss: 2.6780e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 103/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.3168e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00103: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.2778e-05 - mean_absolute_error: 0.0074 - val_loss: 2.5724e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 104/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.0831e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00104: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.0531e-05 - mean_absolute_error: 0.0075 - val_loss: 2.9379e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 105/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.4518e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00105: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.6588e-05 - mean_absolute_error: 0.0071 - val_loss: 4.1446e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 106/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3138e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00106: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.3138e-05 - mean_absolute_error: 0.0069 - val_loss: 4.0203e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 107/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 8.5257e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00107: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.4723e-05 - mean_absolute_error: 0.0074 - val_loss: 9.7751e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 108/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 1.0014e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00108: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.8543e-05 - mean_absolute_error: 0.0079 - val_loss: 2.8755e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 109/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.4921e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00109: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6585e-05 - mean_absolute_error: 0.0071 - val_loss: 6.2272e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 110/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.0010e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00110: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.9901e-05 - mean_absolute_error: 0.0073 - val_loss: 3.9719e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 111/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.3758e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00111: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.2860e-05 - mean_absolute_error: 0.0077 - val_loss: 2.6236e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 112/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8690e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00112: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.8690e-05 - mean_absolute_error: 0.0080 - val_loss: 4.7199e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 113/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 8.4835e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00113: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.3323e-05 - mean_absolute_error: 0.0076 - val_loss: 1.5937e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 114/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.9256e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00114: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.9758e-05 - mean_absolute_error: 0.0074 - val_loss: 2.0192e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 115/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.5425e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00115: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4394e-05 - mean_absolute_error: 0.0071 - val_loss: 3.6359e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 116/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 8.1369e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00116: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.5991e-05 - mean_absolute_error: 0.0074 - val_loss: 7.1980e-05 - val_mean_absolute_error: 0.0082\n",
            "Epoch 117/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4707e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00117: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4707e-05 - mean_absolute_error: 0.0071 - val_loss: 3.3908e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 118/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 8.3990e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00118: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.4035e-05 - mean_absolute_error: 0.0075 - val_loss: 4.6846e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 119/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.4370e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00119: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4596e-05 - mean_absolute_error: 0.0071 - val_loss: 7.8333e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 120/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.6398e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00120: val_loss improved from 0.00002 to 0.00001, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.5679e-05 - mean_absolute_error: 0.0075 - val_loss: 1.3211e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 121/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6918e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00121: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.6918e-05 - mean_absolute_error: 0.0077 - val_loss: 4.0835e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 122/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.8911e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00122: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.9265e-05 - mean_absolute_error: 0.0069 - val_loss: 3.1222e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 123/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1370e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00123: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.1370e-05 - mean_absolute_error: 0.0074 - val_loss: 2.9125e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 124/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.4134e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00124: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.4134e-05 - mean_absolute_error: 0.0077 - val_loss: 3.7845e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 125/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0355e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00125: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.0355e-05 - mean_absolute_error: 0.0073 - val_loss: 4.9554e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 126/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.1340e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00126: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.1018e-05 - mean_absolute_error: 0.0067 - val_loss: 7.4920e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 127/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 8.2121e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00127: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.1843e-05 - mean_absolute_error: 0.0073 - val_loss: 3.0518e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 128/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 8.0407e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00128: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.0228e-05 - mean_absolute_error: 0.0073 - val_loss: 6.8025e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 129/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.7354e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00129: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.9912e-05 - mean_absolute_error: 0.0071 - val_loss: 2.8558e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 130/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 9.7375e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00130: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.5725e-05 - mean_absolute_error: 0.0078 - val_loss: 2.8483e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 131/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9521e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00131: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8987e-05 - mean_absolute_error: 0.0069 - val_loss: 3.9926e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 132/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.1831e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00132: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2498e-05 - mean_absolute_error: 0.0070 - val_loss: 2.4450e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 133/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 8.1296e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00133: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.1640e-05 - mean_absolute_error: 0.0071 - val_loss: 4.4531e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 134/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4136e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00134: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4136e-05 - mean_absolute_error: 0.0072 - val_loss: 3.5174e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 135/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 9.1485e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00135: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.1192e-05 - mean_absolute_error: 0.0077 - val_loss: 2.8256e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 136/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.6926e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00136: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6802e-05 - mean_absolute_error: 0.0071 - val_loss: 6.8138e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 137/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.1805e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00137: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.1754e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8264e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 138/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.2524e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00138: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.1471e-05 - mean_absolute_error: 0.0073 - val_loss: 3.0926e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 139/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.9116e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00139: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.8731e-05 - mean_absolute_error: 0.0071 - val_loss: 4.7403e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 140/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.8190e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00140: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.9363e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0840e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 141/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 1.0432e-04 - mean_absolute_error: 0.0079\n",
            "Epoch 00141: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 1.0227e-04 - mean_absolute_error: 0.0078 - val_loss: 3.6325e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 142/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.8543e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00142: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7115e-05 - mean_absolute_error: 0.0071 - val_loss: 2.9112e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 143/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 8.4277e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00143: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.4303e-05 - mean_absolute_error: 0.0074 - val_loss: 6.9596e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 144/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 8.1342e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00144: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.1288e-05 - mean_absolute_error: 0.0072 - val_loss: 2.8840e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 145/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8700e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00145: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8700e-05 - mean_absolute_error: 0.0069 - val_loss: 2.9584e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 146/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.5864e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00146: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7436e-05 - mean_absolute_error: 0.0071 - val_loss: 1.7060e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 147/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2917e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00147: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2917e-05 - mean_absolute_error: 0.0069 - val_loss: 4.4824e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 148/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.6678e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00148: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6591e-05 - mean_absolute_error: 0.0067 - val_loss: 2.4382e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 149/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.5150e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00149: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4533e-05 - mean_absolute_error: 0.0069 - val_loss: 3.3150e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 150/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.1010e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00150: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0424e-05 - mean_absolute_error: 0.0069 - val_loss: 5.9276e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 151/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 9.5296e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00151: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.4951e-05 - mean_absolute_error: 0.0076 - val_loss: 5.3965e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 152/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.2987e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00152: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2702e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7874e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 153/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.8976e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00153: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.9085e-05 - mean_absolute_error: 0.0072 - val_loss: 7.1807e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 154/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.9855e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00154: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.9786e-05 - mean_absolute_error: 0.0071 - val_loss: 4.2235e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 155/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.1108e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00155: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0993e-05 - mean_absolute_error: 0.0069 - val_loss: 2.2175e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 156/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.0464e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00156: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9815e-05 - mean_absolute_error: 0.0067 - val_loss: 2.3852e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 157/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.4878e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00157: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.5030e-05 - mean_absolute_error: 0.0069 - val_loss: 8.5522e-05 - val_mean_absolute_error: 0.0083\n",
            "Epoch 158/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.4881e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00158: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4318e-05 - mean_absolute_error: 0.0071 - val_loss: 2.5406e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 159/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.1144e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00159: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.0234e-05 - mean_absolute_error: 0.0075 - val_loss: 1.6622e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 160/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.8347e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00160: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8228e-05 - mean_absolute_error: 0.0068 - val_loss: 2.6847e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 161/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9776e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00161: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0320e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4531e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 162/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0500e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00162: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0500e-05 - mean_absolute_error: 0.0066 - val_loss: 4.3338e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 163/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.8487e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00163: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7096e-05 - mean_absolute_error: 0.0071 - val_loss: 2.2243e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 164/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.1224e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00164: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.1060e-05 - mean_absolute_error: 0.0070 - val_loss: 2.9832e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 165/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.6639e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00165: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.6606e-05 - mean_absolute_error: 0.0068 - val_loss: 5.3892e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 166/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.3903e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00166: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.3723e-05 - mean_absolute_error: 0.0067 - val_loss: 2.0417e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 167/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.2662e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00167: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.2835e-05 - mean_absolute_error: 0.0068 - val_loss: 2.5270e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 168/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.8147e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00168: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.8184e-05 - mean_absolute_error: 0.0068 - val_loss: 3.7002e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 169/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9520e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00169: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.9354e-05 - mean_absolute_error: 0.0067 - val_loss: 3.4379e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 170/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5795e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00170: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5795e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1580e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 171/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.5127e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00171: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.5626e-05 - mean_absolute_error: 0.0067 - val_loss: 6.2977e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 172/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.3783e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00172: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.3797e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3666e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 173/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 8.6183e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00173: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.6629e-05 - mean_absolute_error: 0.0075 - val_loss: 5.1920e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 174/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.2586e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00174: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2508e-05 - mean_absolute_error: 0.0065 - val_loss: 2.9715e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 175/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4318e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00175: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.4318e-05 - mean_absolute_error: 0.0073 - val_loss: 8.8557e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 176/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7823e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00176: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.7823e-05 - mean_absolute_error: 0.0065 - val_loss: 4.4089e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 177/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.5996e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00177: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6147e-05 - mean_absolute_error: 0.0066 - val_loss: 2.1794e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 178/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6513e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00178: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6513e-05 - mean_absolute_error: 0.0064 - val_loss: 3.3078e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 179/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 8.2794e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00179: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.2877e-05 - mean_absolute_error: 0.0071 - val_loss: 6.0398e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 180/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.2756e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00180: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2566e-05 - mean_absolute_error: 0.0067 - val_loss: 1.7705e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 181/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.9290e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00181: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9081e-05 - mean_absolute_error: 0.0066 - val_loss: 2.2324e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 182/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.9767e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00182: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.8823e-05 - mean_absolute_error: 0.0071 - val_loss: 2.2523e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 183/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.8466e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00183: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6932e-05 - mean_absolute_error: 0.0070 - val_loss: 2.3912e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 184/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.7767e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00184: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8102e-05 - mean_absolute_error: 0.0067 - val_loss: 2.8232e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 185/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2839e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00185: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.2839e-05 - mean_absolute_error: 0.0070 - val_loss: 1.7324e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 186/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.4941e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00186: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4273e-05 - mean_absolute_error: 0.0070 - val_loss: 3.2212e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 187/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.7107e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00187: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6705e-05 - mean_absolute_error: 0.0067 - val_loss: 4.0012e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 188/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 9.2669e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00188: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 9.2986e-05 - mean_absolute_error: 0.0073 - val_loss: 5.5994e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 189/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 8.2880e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00189: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.2552e-05 - mean_absolute_error: 0.0073 - val_loss: 5.2588e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 190/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3313e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00190: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.3313e-05 - mean_absolute_error: 0.0072 - val_loss: 2.9412e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 191/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4188e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00191: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.4188e-05 - mean_absolute_error: 0.0069 - val_loss: 1.9767e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 192/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.3896e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00192: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3896e-05 - mean_absolute_error: 0.0066 - val_loss: 3.1647e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 193/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.7429e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00193: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8315e-05 - mean_absolute_error: 0.0066 - val_loss: 1.0524e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 194/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 9.1870e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00194: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 9.1782e-05 - mean_absolute_error: 0.0075 - val_loss: 1.8076e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 195/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.9958e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00195: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9197e-05 - mean_absolute_error: 0.0067 - val_loss: 5.9652e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 196/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.0777e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00196: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0436e-05 - mean_absolute_error: 0.0066 - val_loss: 4.4331e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 197/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.7859e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00197: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.7718e-05 - mean_absolute_error: 0.0064 - val_loss: 2.7348e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 198/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.1379e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00198: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.4627e-05 - mean_absolute_error: 0.0068 - val_loss: 5.7551e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 199/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 7.2444e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00199: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2140e-05 - mean_absolute_error: 0.0067 - val_loss: 3.5552e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 200/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9768e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00200: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9355e-05 - mean_absolute_error: 0.0068 - val_loss: 2.2225e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 201/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.7342e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00201: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7652e-05 - mean_absolute_error: 0.0068 - val_loss: 3.1496e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 202/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.2807e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00202: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.1736e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8089e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 203/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.4373e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00203: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4137e-05 - mean_absolute_error: 0.0065 - val_loss: 2.0599e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 204/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.8118e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00204: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.9480e-05 - mean_absolute_error: 0.0067 - val_loss: 2.0000e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 205/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6356e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00205: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6356e-05 - mean_absolute_error: 0.0065 - val_loss: 1.8613e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 206/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.0760e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00206: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0712e-05 - mean_absolute_error: 0.0064 - val_loss: 2.3741e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 207/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.4588e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00207: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4076e-05 - mean_absolute_error: 0.0065 - val_loss: 4.3959e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 208/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.6779e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00208: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7117e-05 - mean_absolute_error: 0.0066 - val_loss: 6.5656e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 209/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4808e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00209: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5566e-05 - mean_absolute_error: 0.0065 - val_loss: 2.3236e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 210/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.7522e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00210: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7719e-05 - mean_absolute_error: 0.0066 - val_loss: 1.7917e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 211/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.7705e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00211: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7692e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8396e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 212/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.2654e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00212: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3116e-05 - mean_absolute_error: 0.0063 - val_loss: 1.7433e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 213/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.5789e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00213: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.6378e-05 - mean_absolute_error: 0.0066 - val_loss: 1.8426e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 214/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 8.4355e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00214: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 8.4599e-05 - mean_absolute_error: 0.0071 - val_loss: 3.0296e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 215/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4378e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00215: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4378e-05 - mean_absolute_error: 0.0066 - val_loss: 3.9368e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 216/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.6936e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00216: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.6050e-05 - mean_absolute_error: 0.0070 - val_loss: 7.3308e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 217/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.7709e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00217: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.7167e-05 - mean_absolute_error: 0.0066 - val_loss: 1.4601e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 218/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.1956e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00218: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1226e-05 - mean_absolute_error: 0.0064 - val_loss: 2.4196e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 219/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.0771e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00219: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0550e-05 - mean_absolute_error: 0.0067 - val_loss: 3.0150e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 220/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.2525e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00220: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2833e-05 - mean_absolute_error: 0.0066 - val_loss: 3.9085e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 221/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.5888e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00221: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.5540e-05 - mean_absolute_error: 0.0068 - val_loss: 2.6841e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 222/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.8239e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00222: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8407e-05 - mean_absolute_error: 0.0066 - val_loss: 4.3897e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 223/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.3350e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00223: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3661e-05 - mean_absolute_error: 0.0065 - val_loss: 1.4755e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 224/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.1869e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00224: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1191e-05 - mean_absolute_error: 0.0065 - val_loss: 2.6978e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 225/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.8613e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00225: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8462e-05 - mean_absolute_error: 0.0063 - val_loss: 2.6675e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 226/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.8917e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00226: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7412e-05 - mean_absolute_error: 0.0068 - val_loss: 1.6441e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 227/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.6342e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00227: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8067e-05 - mean_absolute_error: 0.0066 - val_loss: 5.7549e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 228/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.0954e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00228: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0370e-05 - mean_absolute_error: 0.0066 - val_loss: 2.2716e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 229/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.4393e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00229: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4587e-05 - mean_absolute_error: 0.0064 - val_loss: 2.7670e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 230/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.0472e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00230: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0516e-05 - mean_absolute_error: 0.0064 - val_loss: 1.7029e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 231/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1466e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00231: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.1466e-05 - mean_absolute_error: 0.0067 - val_loss: 3.5974e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 232/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0172e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00232: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0172e-05 - mean_absolute_error: 0.0064 - val_loss: 2.6577e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 233/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.7671e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00233: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7348e-05 - mean_absolute_error: 0.0070 - val_loss: 3.2234e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 234/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 8.1935e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00234: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 8.1631e-05 - mean_absolute_error: 0.0072 - val_loss: 4.3227e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 235/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.6837e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00235: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8679e-05 - mean_absolute_error: 0.0066 - val_loss: 1.3495e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 236/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.9740e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00236: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9211e-05 - mean_absolute_error: 0.0065 - val_loss: 2.2692e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 237/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.2948e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00237: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2295e-05 - mean_absolute_error: 0.0068 - val_loss: 5.0309e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 238/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.0370e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00238: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0760e-05 - mean_absolute_error: 0.0064 - val_loss: 2.9762e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 239/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9339e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00239: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9414e-05 - mean_absolute_error: 0.0066 - val_loss: 3.8665e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 240/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.5898e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00240: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.5956e-05 - mean_absolute_error: 0.0065 - val_loss: 2.8442e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 241/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.6073e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00241: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.5681e-05 - mean_absolute_error: 0.0066 - val_loss: 2.9471e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 242/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.0594e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00242: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 10ms/step - loss: 6.0333e-05 - mean_absolute_error: 0.0063 - val_loss: 3.3676e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 243/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6898e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00243: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6898e-05 - mean_absolute_error: 0.0068 - val_loss: 2.7131e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 244/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.5332e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00244: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5655e-05 - mean_absolute_error: 0.0067 - val_loss: 7.0525e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 245/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.0780e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00245: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0617e-05 - mean_absolute_error: 0.0066 - val_loss: 2.7822e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 246/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.3341e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00246: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3762e-05 - mean_absolute_error: 0.0064 - val_loss: 3.7334e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 247/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.9145e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00247: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8848e-05 - mean_absolute_error: 0.0066 - val_loss: 3.5557e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 248/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 7.1269e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00248: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.0255e-05 - mean_absolute_error: 0.0067 - val_loss: 2.2399e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 249/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 7.2978e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00249: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2088e-05 - mean_absolute_error: 0.0067 - val_loss: 2.4695e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 250/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.7538e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00250: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7593e-05 - mean_absolute_error: 0.0069 - val_loss: 4.9270e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 251/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.3860e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00251: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.3393e-05 - mean_absolute_error: 0.0068 - val_loss: 4.4737e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 252/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 7.7749e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00252: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7799e-05 - mean_absolute_error: 0.0069 - val_loss: 4.5179e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 253/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.2779e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00253: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2327e-05 - mean_absolute_error: 0.0064 - val_loss: 3.2059e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 254/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.8765e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00254: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.9411e-05 - mean_absolute_error: 0.0067 - val_loss: 1.9734e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 255/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.4528e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00255: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.4696e-05 - mean_absolute_error: 0.0065 - val_loss: 3.9906e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 256/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.2288e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00256: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3980e-05 - mean_absolute_error: 0.0065 - val_loss: 1.6447e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 257/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.2200e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00257: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.2092e-05 - mean_absolute_error: 0.0064 - val_loss: 2.3252e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 258/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.3228e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00258: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3650e-05 - mean_absolute_error: 0.0063 - val_loss: 1.8579e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 259/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.1360e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00259: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.1360e-05 - mean_absolute_error: 0.0063 - val_loss: 3.9102e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 260/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.9517e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00260: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9633e-05 - mean_absolute_error: 0.0066 - val_loss: 7.5943e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 261/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.6941e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00261: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.7597e-05 - mean_absolute_error: 0.0061 - val_loss: 2.9027e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 262/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.6947e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00262: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6881e-05 - mean_absolute_error: 0.0065 - val_loss: 2.6716e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 263/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.6180e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00263: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7187e-05 - mean_absolute_error: 0.0066 - val_loss: 6.5927e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 264/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.5404e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00264: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.5688e-05 - mean_absolute_error: 0.0065 - val_loss: 5.4028e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 265/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.8317e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00265: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8089e-05 - mean_absolute_error: 0.0063 - val_loss: 2.7102e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 266/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.7830e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00266: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.7765e-05 - mean_absolute_error: 0.0062 - val_loss: 5.4400e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 267/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.0178e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00267: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0740e-05 - mean_absolute_error: 0.0064 - val_loss: 3.0537e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 268/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2290e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00268: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.2290e-05 - mean_absolute_error: 0.0067 - val_loss: 2.5694e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 269/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0442e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00269: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0442e-05 - mean_absolute_error: 0.0062 - val_loss: 5.4737e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 270/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.5686e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00270: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.6110e-05 - mean_absolute_error: 0.0065 - val_loss: 3.0632e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 271/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.9814e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00271: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0025e-05 - mean_absolute_error: 0.0063 - val_loss: 2.1179e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 272/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.8769e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00272: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.8586e-05 - mean_absolute_error: 0.0061 - val_loss: 4.0424e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 273/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.5732e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00273: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5753e-05 - mean_absolute_error: 0.0067 - val_loss: 2.0350e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 274/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0203e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00274: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0203e-05 - mean_absolute_error: 0.0064 - val_loss: 3.3607e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 275/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2862e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00275: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2862e-05 - mean_absolute_error: 0.0063 - val_loss: 2.6471e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 276/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.3066e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00276: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3066e-05 - mean_absolute_error: 0.0065 - val_loss: 2.8925e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 277/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2484e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00277: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2484e-05 - mean_absolute_error: 0.0063 - val_loss: 2.8821e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 278/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.3169e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00278: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.3169e-05 - mean_absolute_error: 0.0060 - val_loss: 2.9252e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 279/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.8803e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00279: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8604e-05 - mean_absolute_error: 0.0064 - val_loss: 3.7492e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 280/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.8970e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00280: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.8970e-05 - mean_absolute_error: 0.0063 - val_loss: 3.8733e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 281/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.5876e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00281: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.5293e-05 - mean_absolute_error: 0.0062 - val_loss: 2.2639e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 282/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0171e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00282: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0171e-05 - mean_absolute_error: 0.0062 - val_loss: 2.0354e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 283/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.1783e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00283: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1136e-05 - mean_absolute_error: 0.0062 - val_loss: 2.1737e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 284/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.3473e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00284: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3473e-05 - mean_absolute_error: 0.0065 - val_loss: 1.7221e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 285/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4148e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00285: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3817e-05 - mean_absolute_error: 0.0063 - val_loss: 5.8578e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 286/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.8722e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00286: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9439e-05 - mean_absolute_error: 0.0062 - val_loss: 3.3623e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 287/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.6760e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00287: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6495e-05 - mean_absolute_error: 0.0062 - val_loss: 2.4050e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 288/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.5704e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00288: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6650e-05 - mean_absolute_error: 0.0062 - val_loss: 1.6924e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 289/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 7.8433e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00289: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.7636e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1605e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 290/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.8666e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00290: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9126e-05 - mean_absolute_error: 0.0062 - val_loss: 2.6482e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 291/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5924e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00291: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5924e-05 - mean_absolute_error: 0.0065 - val_loss: 3.1472e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 292/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.9061e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00292: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9538e-05 - mean_absolute_error: 0.0063 - val_loss: 2.5071e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 293/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.0989e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00293: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2298e-05 - mean_absolute_error: 0.0062 - val_loss: 1.6987e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 294/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.8964e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00294: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.8334e-05 - mean_absolute_error: 0.0061 - val_loss: 1.4107e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 295/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.0052e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00295: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0598e-05 - mean_absolute_error: 0.0062 - val_loss: 2.3408e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 296/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.9827e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00296: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9785e-05 - mean_absolute_error: 0.0062 - val_loss: 4.7633e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 297/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.3545e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00297: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.3221e-05 - mean_absolute_error: 0.0064 - val_loss: 3.1641e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 298/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.2708e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00298: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.2887e-05 - mean_absolute_error: 0.0063 - val_loss: 4.2892e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 299/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4042e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00299: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4556e-05 - mean_absolute_error: 0.0065 - val_loss: 3.3367e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 300/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 5.8245e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00300: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9407e-05 - mean_absolute_error: 0.0064 - val_loss: 4.3545e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 301/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.3419e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00301: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3570e-05 - mean_absolute_error: 0.0063 - val_loss: 2.4631e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 302/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.7610e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00302: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7192e-05 - mean_absolute_error: 0.0065 - val_loss: 2.9055e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 303/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.8974e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00303: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8997e-05 - mean_absolute_error: 0.0061 - val_loss: 2.0074e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 304/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.0442e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00304: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0200e-05 - mean_absolute_error: 0.0062 - val_loss: 2.1403e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 305/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.9587e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00305: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9454e-05 - mean_absolute_error: 0.0063 - val_loss: 2.0897e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 306/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.9510e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00306: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.9250e-05 - mean_absolute_error: 0.0066 - val_loss: 2.5089e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 307/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.9797e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00307: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9492e-05 - mean_absolute_error: 0.0061 - val_loss: 2.3670e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 308/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 7.9447e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00308: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.8176e-05 - mean_absolute_error: 0.0069 - val_loss: 3.2168e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 309/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.7036e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00309: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6859e-05 - mean_absolute_error: 0.0064 - val_loss: 2.5521e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 310/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.8592e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00310: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8279e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1324e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 311/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.1060e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00311: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1068e-05 - mean_absolute_error: 0.0063 - val_loss: 2.1487e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 312/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.8548e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00312: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8458e-05 - mean_absolute_error: 0.0062 - val_loss: 1.9025e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 313/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.9545e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00313: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.9493e-05 - mean_absolute_error: 0.0067 - val_loss: 1.3899e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 314/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.3015e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00314: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2391e-05 - mean_absolute_error: 0.0063 - val_loss: 1.6603e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 315/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.4512e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00315: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.5186e-05 - mean_absolute_error: 0.0060 - val_loss: 2.6091e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 316/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.7250e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00316: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6642e-05 - mean_absolute_error: 0.0061 - val_loss: 1.8492e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 317/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4988e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00317: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.6344e-05 - mean_absolute_error: 0.0062 - val_loss: 2.3777e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 318/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.6542e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00318: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.7086e-05 - mean_absolute_error: 0.0061 - val_loss: 5.2135e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 319/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.7899e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00319: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8666e-05 - mean_absolute_error: 0.0066 - val_loss: 3.3892e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 320/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.0517e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00320: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0971e-05 - mean_absolute_error: 0.0062 - val_loss: 3.7955e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 321/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.7653e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00321: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8348e-05 - mean_absolute_error: 0.0061 - val_loss: 1.4717e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 322/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.0725e-05 - mean_absolute_error: 0.0058\n",
            "Epoch 00322: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.0512e-05 - mean_absolute_error: 0.0058 - val_loss: 1.4757e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 323/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.4462e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00323: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4093e-05 - mean_absolute_error: 0.0063 - val_loss: 3.1977e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 324/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.4352e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00324: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3327e-05 - mean_absolute_error: 0.0063 - val_loss: 2.1554e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 325/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 5.4248e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00325: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.3994e-05 - mean_absolute_error: 0.0059 - val_loss: 1.8047e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 326/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.8277e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00326: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.7664e-05 - mean_absolute_error: 0.0064 - val_loss: 1.8079e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 327/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.7825e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00327: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.7569e-05 - mean_absolute_error: 0.0062 - val_loss: 2.8543e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 328/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.2326e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00328: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1718e-05 - mean_absolute_error: 0.0062 - val_loss: 1.3622e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 329/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.5034e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00329: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.5703e-05 - mean_absolute_error: 0.0060 - val_loss: 1.8570e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 330/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.3294e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00330: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3803e-05 - mean_absolute_error: 0.0064 - val_loss: 2.5008e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 331/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 7.7441e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00331: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 7.6125e-05 - mean_absolute_error: 0.0068 - val_loss: 5.1877e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 332/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.9500e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00332: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8693e-05 - mean_absolute_error: 0.0065 - val_loss: 1.3785e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 333/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.0050e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00333: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.9849e-05 - mean_absolute_error: 0.0062 - val_loss: 2.2064e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 334/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.5413e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00334: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.5486e-05 - mean_absolute_error: 0.0062 - val_loss: 1.8273e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 335/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.3814e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00335: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.4026e-05 - mean_absolute_error: 0.0061 - val_loss: 1.9263e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 336/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 6.0733e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00336: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0566e-05 - mean_absolute_error: 0.0061 - val_loss: 3.0529e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 337/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.5335e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00337: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.5492e-05 - mean_absolute_error: 0.0062 - val_loss: 3.5871e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 338/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.1304e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00338: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.1428e-05 - mean_absolute_error: 0.0059 - val_loss: 2.3200e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 339/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.3463e-05 - mean_absolute_error: 0.0058\n",
            "Epoch 00339: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.3168e-05 - mean_absolute_error: 0.0058 - val_loss: 3.0100e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 340/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.5580e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00340: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.5745e-05 - mean_absolute_error: 0.0060 - val_loss: 6.5308e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 341/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.5501e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00341: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6299e-05 - mean_absolute_error: 0.0060 - val_loss: 2.4807e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 342/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.7789e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00342: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.7789e-05 - mean_absolute_error: 0.0062 - val_loss: 3.7132e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 343/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4928e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00343: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.4455e-05 - mean_absolute_error: 0.0063 - val_loss: 2.0080e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 344/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.4746e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00344: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.5313e-05 - mean_absolute_error: 0.0059 - val_loss: 1.8345e-05 - val_mean_absolute_error: 0.0021\n",
            "Epoch 345/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.3642e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00345: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 10ms/step - loss: 5.3622e-05 - mean_absolute_error: 0.0059 - val_loss: 4.5031e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 346/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.1867e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00346: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.1867e-05 - mean_absolute_error: 0.0062 - val_loss: 5.3828e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 347/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.1162e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00347: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.0569e-05 - mean_absolute_error: 0.0061 - val_loss: 1.8420e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 348/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.5213e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00348: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.4484e-05 - mean_absolute_error: 0.0065 - val_loss: 1.9952e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 349/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.7990e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00349: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.7962e-05 - mean_absolute_error: 0.0060 - val_loss: 3.6600e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 350/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.8061e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00350: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.9383e-05 - mean_absolute_error: 0.0060 - val_loss: 4.3437e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 351/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.3630e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00351: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.4296e-05 - mean_absolute_error: 0.0059 - val_loss: 2.5752e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 352/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.4818e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00352: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.4974e-05 - mean_absolute_error: 0.0059 - val_loss: 1.3988e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 353/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.6524e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00353: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6129e-05 - mean_absolute_error: 0.0060 - val_loss: 1.5548e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 354/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.8843e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00354: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8378e-05 - mean_absolute_error: 0.0062 - val_loss: 2.8107e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 355/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0630e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00355: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0630e-05 - mean_absolute_error: 0.0062 - val_loss: 1.9130e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 356/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.8613e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00356: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8407e-05 - mean_absolute_error: 0.0061 - val_loss: 5.7784e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 357/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.8983e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00357: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.8690e-05 - mean_absolute_error: 0.0062 - val_loss: 1.5357e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 358/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.9173e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00358: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.8718e-05 - mean_absolute_error: 0.0067 - val_loss: 2.6244e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 359/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.5253e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00359: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.4971e-05 - mean_absolute_error: 0.0062 - val_loss: 7.9362e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 360/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.0982e-05 - mean_absolute_error: 0.0058\n",
            "Epoch 00360: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.0688e-05 - mean_absolute_error: 0.0058 - val_loss: 1.5474e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 361/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.1794e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00361: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.1570e-05 - mean_absolute_error: 0.0060 - val_loss: 3.4600e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 362/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.8846e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00362: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8846e-05 - mean_absolute_error: 0.0059 - val_loss: 1.9861e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 363/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.9502e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00363: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8802e-05 - mean_absolute_error: 0.0061 - val_loss: 4.2101e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 364/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.6424e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00364: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6563e-05 - mean_absolute_error: 0.0060 - val_loss: 4.2422e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 365/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.9993e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00365: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 7.0600e-05 - mean_absolute_error: 0.0065 - val_loss: 3.2207e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 366/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.0361e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00366: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0637e-05 - mean_absolute_error: 0.0061 - val_loss: 2.6346e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 367/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.6170e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00367: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0452e-05 - mean_absolute_error: 0.0063 - val_loss: 4.8028e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 368/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.9530e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00368: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.9530e-05 - mean_absolute_error: 0.0062 - val_loss: 2.2554e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 369/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.9286e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00369: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.9217e-05 - mean_absolute_error: 0.0061 - val_loss: 1.6012e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 370/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.1421e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00370: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1172e-05 - mean_absolute_error: 0.0061 - val_loss: 1.4918e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 371/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 5.1916e-05 - mean_absolute_error: 0.0058\n",
            "Epoch 00371: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.1793e-05 - mean_absolute_error: 0.0058 - val_loss: 1.2912e-05 - val_mean_absolute_error: 0.0021\n",
            "Epoch 372/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 6.4493e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00372: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.3415e-05 - mean_absolute_error: 0.0061 - val_loss: 2.2962e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 373/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.6919e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00373: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.6840e-05 - mean_absolute_error: 0.0061 - val_loss: 2.9780e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 374/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 5.9199e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00374: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.0137e-05 - mean_absolute_error: 0.0062 - val_loss: 1.6190e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 375/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.5238e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00375: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4351e-05 - mean_absolute_error: 0.0062 - val_loss: 2.7485e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 376/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.8461e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00376: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8327e-05 - mean_absolute_error: 0.0062 - val_loss: 3.1900e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 377/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.3147e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00377: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.3391e-05 - mean_absolute_error: 0.0060 - val_loss: 3.1368e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 378/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4866e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00378: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4866e-05 - mean_absolute_error: 0.0065 - val_loss: 3.0743e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 379/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 6.4409e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00379: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 6.3541e-05 - mean_absolute_error: 0.0063 - val_loss: 1.5465e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 380/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4740e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00380: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4740e-05 - mean_absolute_error: 0.0063 - val_loss: 4.0587e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 381/400\n",
            "119/124 [===========================>..] - ETA: 0s - loss: 6.3035e-05 - mean_absolute_error: 0.0063\n",
            "Epoch 00381: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.5965e-05 - mean_absolute_error: 0.0063 - val_loss: 2.8822e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 382/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.6580e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00382: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6580e-05 - mean_absolute_error: 0.0060 - val_loss: 1.7623e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 383/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.6188e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00383: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.4917e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1384e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 384/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.6409e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00384: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.6129e-05 - mean_absolute_error: 0.0060 - val_loss: 1.9443e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 385/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.2415e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00385: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.2119e-05 - mean_absolute_error: 0.0059 - val_loss: 1.5709e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 386/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.6313e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00386: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6891e-05 - mean_absolute_error: 0.0060 - val_loss: 2.1309e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 387/400\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.8701e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00387: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8701e-05 - mean_absolute_error: 0.0060 - val_loss: 3.7777e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 388/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.2499e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00388: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.3405e-05 - mean_absolute_error: 0.0059 - val_loss: 1.7047e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 389/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.6214e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00389: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6430e-05 - mean_absolute_error: 0.0061 - val_loss: 4.1494e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 390/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.1916e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00390: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.2743e-05 - mean_absolute_error: 0.0060 - val_loss: 1.5160e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 391/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 5.6398e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00391: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6106e-05 - mean_absolute_error: 0.0060 - val_loss: 1.6012e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 392/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.8621e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00392: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.8364e-05 - mean_absolute_error: 0.0062 - val_loss: 1.6787e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 393/400\n",
            "117/124 [===========================>..] - ETA: 0s - loss: 6.0554e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00393: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 9ms/step - loss: 5.9288e-05 - mean_absolute_error: 0.0061 - val_loss: 1.8893e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 394/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.1623e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00394: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2026e-05 - mean_absolute_error: 0.0063 - val_loss: 3.4041e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 395/400\n",
            "122/124 [============================>.] - ETA: 0s - loss: 6.2477e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00395: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.2360e-05 - mean_absolute_error: 0.0061 - val_loss: 1.5652e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 396/400\n",
            "121/124 [============================>.] - ETA: 0s - loss: 5.2494e-05 - mean_absolute_error: 0.0059\n",
            "Epoch 00396: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.2537e-05 - mean_absolute_error: 0.0059 - val_loss: 3.7423e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 397/400\n",
            "118/124 [===========================>..] - ETA: 0s - loss: 5.9828e-05 - mean_absolute_error: 0.0062\n",
            "Epoch 00397: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-08-17_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1266e-05 - mean_absolute_error: 0.0062 - val_loss: 1.1372e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 398/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 5.6807e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00398: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.6336e-05 - mean_absolute_error: 0.0061 - val_loss: 2.0098e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 399/400\n",
            "123/124 [============================>.] - ETA: 0s - loss: 5.8046e-05 - mean_absolute_error: 0.0061\n",
            "Epoch 00399: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 5.7977e-05 - mean_absolute_error: 0.0061 - val_loss: 3.6419e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 400/400\n",
            "120/124 [============================>.] - ETA: 0s - loss: 6.1666e-05 - mean_absolute_error: 0.0060\n",
            "Epoch 00400: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 6.1135e-05 - mean_absolute_error: 0.0060 - val_loss: 1.1788e-05 - val_mean_absolute_error: 0.0021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4A99-udbzjt",
        "colab_type": "text"
      },
      "source": [
        "Após o término do treinamento (ou durante o treinamento), \n",
        "\n",
        "tente executar o tensorboard usando este comando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seOB2aIhbvqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "59640a79-6b69-470c-8acc-1acf015164a2"
      },
      "source": [
        "tensorboard --logdir=\"logs\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-87357480c861>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=\"logs\"\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da8_UCPyb5On",
        "colab_type": "text"
      },
      "source": [
        "Testando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghaXzbzIb6lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "\n",
        "# constroi o modelo\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9I_wK0mcBmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5bac2ba-4c21-432b-fe32-1b03692d9f94"
      },
      "source": [
        "# avaliar o modfelo\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calcular o erro absoluto médio (escala inversa)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.720011511418901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0i_E9FGrQFd",
        "colab_type": "text"
      },
      "source": [
        "Nada mal, em média, o preço previsto está apenas longe do preço real em 4,42 $.\n",
        "\n",
        "Tudo bem, vamos tentar prever o preço futuro do Apple Stock Market"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7E6wA6TcGVl",
        "colab_type": "text"
      },
      "source": [
        "# Agora vamos testar nosso modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOt6liIYcHXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d9d8e65-1dcf-4492-f60a-71349cc94c49"
      },
      "source": [
        "'''# validado o modelo\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calcular o erro absoluto médio (escala inversa)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.720011511418901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7-0atj0cUHE",
        "colab_type": "text"
      },
      "source": [
        "Tentando prever o preço futuro do mercado de ações da Apple:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVa7-JcFcQUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, data, classification=False):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5eSjNO7cfrF",
        "colab_type": "text"
      },
      "source": [
        "Esta função usa a variável last_sequence que salvamos na função load_data (), \n",
        "\n",
        "que é basicamente a última sequência de preços, usamos para prever o próximo preço, vamos chamar isso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKVcmfYciCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3133e183-9e30-4dd4-893c-6836e2bece49"
      },
      "source": [
        "# prever o preço futuro\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 455.27$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7a_39Jxcs59",
        "colab_type": "text"
      },
      "source": [
        "Soa interessante ! O último preço foi de 298,45.  a modelo diz que no dia seguinte será  de 455.27 $. \n",
        "\n",
        "O modelo acabou de usar 50 dias de recursos para conseguir esse valor, vamos traçar os preços e ver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gh1XAgmcku3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    # últimos 200 dias, fique à vontade para editar isso\n",
        "    plt.title('AAPL')\n",
        "    plt.plot(y_test[-200:], c='b')\n",
        "    plt.plot(y_pred[-200:], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8aQmMeTdHPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a62587f9-a9c9-43c0-deed-f962948e60fe"
      },
      "source": [
        "plot_graph(model, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOf1KYu4sxYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76003c15-c202-4d5a-d113-c8cd684520ad"
      },
      "source": [
        "print(f\"Future price after {LOOKUP_STEP} \n",
        "      days is {future_price:.2f}$\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 455.27$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUdbIyodMu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "    return accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAycNC5vdX6H",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos chamar a função"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2OWT2WdOb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22bdddf3-76cb-4043-82fb-c063a6bffee7"
      },
      "source": [
        "print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", get_accuracy(model, data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: Accuracy Score: 0.5323232323232323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j1dFMTOdgps",
        "colab_type": "text"
      },
      "source": [
        "Conclusão\n",
        "\n",
        "Tudo bem, é isso para este tutorial, você pode ajustar os parâmetros e ver como pode melhorar o desempenho do modelo, tentar treinar em mais épocas, digamos 500 ou mais, aumentar ou diminuir o BATCH_SIZE e ver se muda para melhor, ou experimente N_STEPS e LOOKUP_STEPS e veja qual combinação funciona melhor.\n",
        "\n",
        "Você também pode alterar os parâmetros do modelo, como aumentar o número de camadas ou o número de unidades LSTM, ou mesmo experimentar a célula GRU em vez de LSTM.\n",
        "\n",
        "Observe que existem outros recursos e indicadores a serem usados, a fim de melhorar a previsão, muitas vezes é conhecido o uso de algumas outras informações como recursos, como indicadores técnicos, a inovação do produto da empresa, taxa de juros, taxa de câmbio, políticas públicas, o notícias da web e financeiras e até mesmo o número de funcionários!\n",
        "\n",
        "Eu encorajo você a mudar a arquitetura do modelo, tentar usar modelos CNNs ou Seq2Seq, ou mesmo adicionar LSTMs bidirecionais a este modelo existente, veja se você pode melhorá-lo!\n",
        "\n",
        "Além disso, use diferentes mercados de ações, verifique a página do [Yahoo Finance](https://finance.yahoo.com/) e veja qual você realmente deseja!\n",
        "\n",
        "Se você não estiver usando um notebook ou um shell interativo, dividi o código em diferentes arquivos Python, cada um para seu propósito, verifique  [aqui](https://www.thepythoncode.com/code/stock-price-prediction-in-python-using-tensorflow-2-and-keras)."
      ]
    }
  ]
}